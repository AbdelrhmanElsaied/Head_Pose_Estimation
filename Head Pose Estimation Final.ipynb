{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xw1HD9F6aB5h"
   },
   "outputs": [],
   "source": [
    "\n",
    "# install mediapipe library\n",
    "%pip install mediapipe\n",
    "\n",
    "%pip install tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7uEmufZ33yQt"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEY7ScK1ak9g"
   },
   "source": [
    "**Importing Needed Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7lV5bn_gaMw_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os,cv2,math,glob,random\n",
    "import scipy.io as sio\n",
    "from math import cos, sin\n",
    "from pathlib import Path\n",
    "import mediapipe\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "#from google.colab.patches import cv2_imshow # only when you use google colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVd3uKLIa1SW"
   },
   "source": [
    "**Download and load Data**\n",
    "\n",
    "\n",
    "*   Data is \n",
    "*   List item\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQjvjzwUfXeW"
   },
   "source": [
    "-the link if you want to directly download the data\n",
    "http://www.cbsr.ia.ac.cn/users/xiangyuzhu/projects/3DDFA/Database/AFLW2000-3D.zip\n",
    "\n",
    "-OR you can download it from google drive using id which is google drive gives to every file on it\n",
    "(you can find the id of your file in the place of * in url such as: https://drive.google.com/file/d/**********************/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JsVme99zaXmY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x4dxvJXIaffH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kfpXYn3hPWy"
   },
   "source": [
    "**Preparing Data for Training by these steps**\n",
    "\n",
    "*   picking X_points\n",
    "*   picking Y_points\n",
    "*   picking labels\n",
    "*   Which files that MediaPipe able to detect the face in images\n",
    "\n",
    "-For simplicity We will just take X,Y points from data ignoring Z points and using this points for training Ml model\n",
    "\n",
    "-Dont worry It will be explained when we reach to this part of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "_vztTx3MhOB6",
    "outputId": "4c5df691-eda6-4e1e-b2ba-c2ecef6e3d76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nor you can use this line insted\\nfile_names = sorted([Path(f).stem for f in glob.glob(\"..\\\\AFLW2000*.jpg\")])\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_points = []\n",
    "Y_points = []\n",
    "labels = []\n",
    "detected_files = []\n",
    "\n",
    "'''\n",
    "if you take a look of data files you will find 2000 images and there are matlab files\n",
    "for every image named the same name of image that it belongs to\n",
    "'''\n",
    "# now we will create a list extracting all the names of images (the same name of matlab files)\n",
    "file_names = sorted([Path(f).stem for f in glob.glob(\"AFLW2000/*.mat\")])\n",
    "\n",
    "''' \n",
    "or you can use this line insted\n",
    "file_names = sorted([Path(f).stem for f in glob.glob(\"..\\AFLW2000*.jpg\")])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_names) # this will show you the number of images in the folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWsF3Iy-vz9G"
   },
   "source": [
    "using mediapipe we can generating the landmarks into the faces\n",
    "\n",
    "this mean we can extract the features from images using it \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "aCcFyKZBGlJV",
    "outputId": "f07ca04e-1823-442a-9194-2d3ce3d7bb5d"
   },
   "outputs": [],
   "source": [
    "# first let's try open image useng CV2\n",
    "imagetest1 = cv2.imread('AFLW2000/image00053.jpg') # read the image\n",
    "cv2.imshow('image test 1',imagetest1) # display the image\n",
    "cv2.waitKey(0) \n",
    "  \n",
    "#closing all open windows \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "caJ3q8J3IMMT",
    "outputId": "742f076c-d9c0-4185-f3c5-32b600f83f43"
   },
   "outputs": [],
   "source": [
    "'''\n",
    " note: Any photo is only array of pixels and the pixel have 3 values express the color from 0 to 255\n",
    " i will show you this array\n",
    "\n",
    "'''\n",
    "imagetest1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AhPb-khsIsIc",
    "outputId": "24c7c37a-2125-4f83-e96b-f470958a3fa2"
   },
   "outputs": [],
   "source": [
    "# first 2 number is the number of pixels that photo consist of\n",
    "imagetest1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 704
    },
    "id": "S1AE8vAtIx9e",
    "outputId": "ae0f38d0-479a-42ee-affe-5f23420ca74a"
   },
   "outputs": [],
   "source": [
    "# other image to compare number of pixels\n",
    "imagetest2 = cv2.imread('robert_downey_jr.jpg')\n",
    "cv2.imshow(\"image test 2\",imagetest2)\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L3vVrFg-JQM5",
    "outputId": "52b83b86-f023-47a0-eec2-3570dc25ebf7"
   },
   "outputs": [],
   "source": [
    "imagetest2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qyg1EjUMJGRc",
    "outputId": "20c43a69-e3d3-4fe5-fc78-fd1e5433f285"
   },
   "outputs": [],
   "source": [
    "imagetest2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dl2Z-Kd3JWg7"
   },
   "outputs": [],
   "source": [
    "# Its very obvious to say that the image have more pixels is bigger \n",
    "# Note: first num is Y axis and second is X axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1V9yG2EoJWje"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XVoBYI7IJWmP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101,
     "referenced_widgets": [
      "199157f2da9f415c9580375d918490e4",
      "619c2167a7a74b5bb9e7305470298210",
      "ee03e3c503d24af7aad0ee59edee3194",
      "63a19b88efc84fb6a8d4f89690e5ab20",
      "4a26d0eced5742b2a0cf838654d3cb0e",
      "21867022fd64479abff2c9fb8a494e12",
      "a262a954ca0f41898243c68df10c4f4d",
      "191d4705883b4147ab9061dc72745e5b",
      "65e812e3e67d4eb697b8779f411c79e4",
      "a5cdcc9dbd6b427182d352e084e66e3d",
      "d1edefd6e58a4aa38268295ed14a03fe"
     ]
    },
    "id": "AllYLjADmtK4",
    "outputId": "812ebecc-9db8-416f-dc72-dcd33510a5fd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bbfb464116a402a9760fe55002bf5f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1853, 468)\n",
      "(1853, 468)\n",
      "(1853, 3)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "face_mesh sub-module exposes the function necessary to do the face detection and landmarks estimation\n",
    "\n",
    "'''\n",
    "faceModule = mediapipe.solutions.face_mesh \n",
    "\n",
    "# looping over the file names to load the images and their corresponding mat file\n",
    "for filename in tqdm(file_names):\n",
    "\n",
    "  '''\n",
    "  We are going to wrap the creation of this object on a with statement\n",
    "  This ensures the resources are freed after we no longer need the object\n",
    "  without it you memory maybe exceeds its storage capacit\n",
    "  '''\n",
    "  with faceModule.FaceMesh(static_image_mode=True) as faces: # creating object from FaceMesh class\n",
    "\n",
    "    # loading the image\n",
    "    image = cv2.imread('AFLW2000/'+filename+'.jpg')\n",
    "\n",
    "    '''\n",
    "    -processing the image to detect the face and then generating the landmarks (468 for each x,y,z)\n",
    "    -note: cv2 use The BGR color model insted of RGB so we must convert the image to this color model\n",
    "    '''\n",
    "    results = faces.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # results.multi_face_landmarks -----> returns list of dict with all landmarks\n",
    "    if results.multi_face_landmarks != None: # check that mediapipe can generate landmarks and if true we will use this image\n",
    "      # appending the file names where have been detected.\n",
    "          detected_files.append(filename)\n",
    "          # detecting the face\n",
    "          face = results.multi_face_landmarks[0]\n",
    "\n",
    "          # initializing two lists to store the points for the image.\n",
    "          # like we siad before we will use x,y only \n",
    "          X = []\n",
    "          Y = []\n",
    "          # looping over the 468 points of x and y\n",
    "          for landmark in face.landmark:\n",
    "              x = landmark.x\n",
    "              y = landmark.y\n",
    "              ### note: the x and y values are scaled to the their width and height so we will get back their actual value in the image.\n",
    "              shape = image.shape\n",
    "              relative_x = int(x * shape[1])\n",
    "              relative_y = int(y * shape[0])\n",
    "              # X_features\n",
    "              X.append(relative_x)\n",
    "              # Y_features\n",
    "              Y.append(relative_y)\n",
    "\n",
    "          # converting the lists to numpy arrays\n",
    "          X = np.array(X)\n",
    "          Y = np.array(Y)\n",
    "          # appending the points of the images in the list of all image points\n",
    "          X_points.append(X)\n",
    "          Y_points.append(Y)\n",
    "\n",
    "\n",
    "          '''\n",
    "          loading the mat file to extract the labels (pitch,yaw,roll)\n",
    "          the result in mat_file is dict, we only need first 3 items which represent \n",
    "          the three angles (pitch,yaw,roll) and those are the labels\n",
    "          '''\n",
    "          mat_file = sio.loadmat('AFLW2000/'+filename+'.mat')\n",
    "\n",
    "\n",
    "          # extracting the labels 3 angels\n",
    "          pose_para = mat_file[\"Pose_Para\"][0][:3]\n",
    "          # appending the 3 angels to labels list\n",
    "          labels.append(pose_para)\n",
    "\n",
    "\n",
    "# converting features and labels to 2D array\n",
    "X_points = np.array(X_points)\n",
    "Y_points = np.array(Y_points)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# the first label (pitch)\n",
    "pitch_label = labels[:,0]\n",
    "# the first label (yaw)\n",
    "yaw_label = labels[:,1]\n",
    "# the first label (roll)\n",
    "roll_label = labels[:,2]\n",
    "print(X_points.shape)\n",
    "print(Y_points.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1853"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(detected_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAnJ-6zPgnsa"
   },
   "source": [
    "Now we have the data (features and labels) let's Preprocessing this data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1O83fS6BhCU8"
   },
   "source": [
    "**Preprocessing the data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rmbCkM-xhOHD",
    "outputId": "4e8bdfe4-b8c8-41ec-cf48-ac80363dc4c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1853, 468)\n",
      "(1853, 468)\n",
      "(1853, 936)\n"
     ]
    }
   ],
   "source": [
    "# center 99\n",
    "# max = 10\n",
    "# min = 171\n",
    "# centering the data arround the 99th point \n",
    "Center_X = X_points - X_points[:,99].reshape(-1,1)\n",
    "Center_Y = Y_points - Y_points[:,99].reshape(-1,1)\n",
    "\n",
    "# normalizing the data to be in the same scale by dividing over the distance between point 10 and point 171\n",
    "X_171 = X_points[:,171]\n",
    "X_10 = X_points[:,10]\n",
    "Y_171 = Y_points[:,171]\n",
    "Y_10 = Y_points[:,10]\n",
    "# computing the distance\n",
    "distance = np.linalg.norm(np.array((X_10,Y_10)) - np.array((X_171,Y_171)),axis = 0).reshape(-1,1)\n",
    "Norm_X = Center_X / distance\n",
    "Norm_Y = Center_Y / distance\n",
    "\n",
    "### if you want to choose specific columns from the data\n",
    "Final_X = Norm_X\n",
    "Final_Y = Norm_Y\n",
    "\n",
    "print(Final_X.shape)\n",
    "print(Final_Y.shape)\n",
    "\n",
    "# concatinating the X and Y points to form the compelete features\n",
    "features = np.hstack([Final_X,Final_Y])\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "featuresDF=pd.DataFrame(features)\n",
    "featuresDF.to_csv('features.csv',index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPXOv6QGrji2"
   },
   "source": [
    "**pitch ML model using Tpot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_DF=pd.DataFrame(pitch_label)   # creating a dataframe from the labels\n",
    "pitch_DF.to_csv('pitch.csv',index=False)  # saving the dataframe to a csv file\n",
    "\n",
    "yaw_DF = pd.DataFrame(yaw_label)\n",
    "yaw_DF.to_csv('yaw.csv',index=False)\n",
    "\n",
    "roll_DF = pd.DataFrame(roll_label)\n",
    "roll_DF.to_csv('roll.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.399231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.470065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.184650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.175379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.026812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>-0.306358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>-0.367547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>-0.156035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>-0.197102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>-0.015552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1853 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0    -0.399231\n",
       "1     0.470065\n",
       "2    -0.184650\n",
       "3    -0.175379\n",
       "4    -0.026812\n",
       "...        ...\n",
       "1848 -0.306358\n",
       "1849 -0.367547\n",
       "1850 -0.156035\n",
       "1851 -0.197102\n",
       "1852 -0.015552\n",
       "\n",
       "[1853 rows x 1 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pitch_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.189533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.881137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.299208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>-0.283822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>-0.429723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>0.567114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>-0.070430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>-0.180126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1853 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0     0.018227\n",
       "1     1.189533\n",
       "2     0.881137\n",
       "3     0.299208\n",
       "4     0.011965\n",
       "...        ...\n",
       "1848 -0.283822\n",
       "1849 -0.429723\n",
       "1850  0.567114\n",
       "1851 -0.070430\n",
       "1852 -0.180126\n",
       "\n",
       "[1853 rows x 1 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yaw_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.085676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.300959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.236852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.373374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.220662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>0.038554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>0.122791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>-0.108536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>0.105118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>-0.024546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1853 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0     0.085676\n",
       "1     0.300959\n",
       "2    -0.236852\n",
       "3    -0.373374\n",
       "4    -0.220662\n",
       "...        ...\n",
       "1848  0.038554\n",
       "1849  0.122791\n",
       "1850 -0.108536\n",
       "1851  0.105118\n",
       "1852 -0.024546\n",
       "\n",
       "[1853 rows x 1 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roll_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting in ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "IprnKiZgpKwi"
   },
   "outputs": [],
   "source": [
    "# splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train_pitch,x_test_pitch,y_train_pitch,y_test_pitch = train_test_split(featuresDF,pitch_DF,test_size = 0.2,random_state = 20)\n",
    "\n",
    "\n",
    "x_train_yaw,x_test_yaw,y_train_yaw,y_test_yaw = train_test_split(featuresDF,yaw_DF,test_size = 0.2,random_state = 20)\n",
    "\n",
    "\n",
    "x_train_roll,x_test_roll,y_train_roll,y_test_roll = train_test_split(featuresDF,roll_DF,test_size = 0.2,random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "HBu1zAETcTER"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pitch Winner Model:  SVR(C=100, kernel='poly')\n",
      "Train Error:  0.09068371104077763\n",
      "Validation Error:  0.09771809279218029\n"
     ]
    }
   ],
   "source": [
    "svr_parameters = {'kernel':['linear', 'poly', 'rbf', 'sigmoid'],'C':[0.01,0.1,1,10,100]}\n",
    "# grid search pitch\n",
    "svr = SVR()\n",
    "svr_gs_pitch = GridSearchCV(estimator = svr,param_grid = svr_parameters)\n",
    "svr_gs_pitch.fit(x_train_pitch, y_train_pitch)\n",
    "svr_winner_pitch = svr_gs_pitch.best_estimator_\n",
    "print(\"Pitch Winner Model: \",svr_winner_pitch)\n",
    "print(\"Train Error: \",mean_absolute_error(svr_winner_pitch.predict(x_train_pitch),y_train_pitch))\n",
    "print(\"Validation Error: \",mean_absolute_error(svr_winner_pitch.predict(x_test_pitch),y_test_pitch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yaw Winner Model:  SVR(C=100, kernel='poly')\n",
      "Train Error:  0.06833417314046158\n",
      "Validation Error:  0.07244099823750216\n"
     ]
    }
   ],
   "source": [
    "# grid search yaw\n",
    "svr = SVR()\n",
    "svr_gs_yaw = GridSearchCV(estimator = svr,param_grid = svr_parameters)\n",
    "svr_gs_yaw.fit(x_train_yaw, y_train_yaw)\n",
    "svr_winner_yaw = svr_gs_yaw.best_estimator_\n",
    "print(\"Yaw Winner Model: \",svr_winner_yaw)\n",
    "print(\"Train Error: \",mean_absolute_error(svr_winner_yaw.predict(x_train_yaw),y_train_yaw))\n",
    "print(\"Validation Error: \",mean_absolute_error(svr_winner_yaw.predict(x_test_yaw),y_test_yaw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yaw Winner Model:  SVR(C=10)\n",
      "Train Error:  0.07640400253374444\n",
      "Validation Error:  0.07844118236957526\n"
     ]
    }
   ],
   "source": [
    "# grid search roll\n",
    "svr = SVR()\n",
    "svr_gs_roll = GridSearchCV(estimator = svr,param_grid = svr_parameters)\n",
    "svr_gs_roll.fit(x_train_roll, y_train_roll)\n",
    "svr_winner_roll = svr_gs_roll.best_estimator_\n",
    "print(\"Yaw Winner Model: \",svr_winner_roll)\n",
    "print(\"Train Error: \",mean_absolute_error(svr_winner_roll.predict(x_train_roll),y_train_roll))\n",
    "print(\"Validation Error: \",mean_absolute_error(svr_winner_roll.predict(x_test_roll),y_test_roll))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "draw tha axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_axis(img, pitch,yaw,roll, tdx=None, tdy=None, size = 100):\n",
    "\n",
    "    yaw = -yaw\n",
    "    if tdx != None and tdy != None:\n",
    "        tdx = tdx\n",
    "        tdy = tdy\n",
    "    else:\n",
    "        height, width = img.shape[:2]\n",
    "        tdx = width / 2\n",
    "        tdy = height / 2\n",
    "\n",
    "    # X-Axis pointing to right. drawn in red\n",
    "    x1 = size * (cos(yaw) * cos(roll)) + tdx\n",
    "    y1 = size * (cos(pitch) * sin(roll) + cos(roll) * sin(pitch) * sin(yaw)) + tdy\n",
    "\n",
    "    # Y-Axis | drawn in green\n",
    "    #        v\n",
    "    x2 = size * (-cos(yaw) * sin(roll)) + tdx\n",
    "    y2 = size * (cos(pitch) * cos(roll) - sin(pitch) * sin(yaw) * sin(roll)) + tdy\n",
    "\n",
    "    # Z-Axis (out of the screen) drawn in blue\n",
    "    x3 = size * (sin(yaw)) + tdx\n",
    "    y3 = size * (-cos(yaw) * sin(pitch)) + tdy\n",
    "\n",
    "    cv2.line(img, (int(tdx), int(tdy)), (int(x1),int(y1)),(0,0,255),3)\n",
    "    cv2.line(img, (int(tdx), int(tdy)), (int(x2),int(y2)),(0,255,0),3)\n",
    "    cv2.line(img, (int(tdx), int(tdy)), (int(x3),int(y3)),(255,0,0),2)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw axis on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_axis_on_image(random_file = 'image00053'):\n",
    "    immage = cv2.imread('AFLW2000/'+random_file+'.jpg')\n",
    "    mat_file = sio.loadmat('AFLW2000/'+random_file+'.mat')\n",
    "\n",
    "    pose_para = mat_file[\"Pose_Para\"][0][:3]\n",
    "\n",
    "    pitch_label = pose_para[0]\n",
    "    yaw_label = pose_para[1]\n",
    "    roll_label = pose_para[2]\n",
    "\n",
    "    cv2.imshow(\"show image\",draw_axis(immage,pitch_label,yaw_label,roll_label))\n",
    "    cv2.imshow(\"show image\",immage)\n",
    "    cv2.waitKey(0) \n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_axis_and_points(random_file = 'image00053'):\n",
    "    faceModule = mediapipe.solutions.face_mesh\n",
    "    with faceModule.FaceMesh(static_image_mode=True) as faces:\n",
    "        image = cv2.imread('AFLW2000/'+random_file+'.jpg')\n",
    "        results = faces.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        if results.multi_face_landmarks != None: \n",
    "            for face in results.multi_face_landmarks:\n",
    "                for landmark in face.landmark:\n",
    "                    x = landmark.x\n",
    "                    y = landmark.y\n",
    "                # note: the x and y values are scaled to the their width and height so we will get back their actual value in the image\n",
    "                    shape = image.shape \n",
    "                    relative_x = int(x * shape[1])\n",
    "                    relative_y = int(y * shape[0])\n",
    "\n",
    "                    \n",
    "                # cv2.putText(image, str(relative_y), (int(relative_x),int(relative_y)), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,255,0), 2)\n",
    "                    cv2.circle(image, (relative_x, relative_y), radius=1, color=(0, 255, 0), thickness=2)\n",
    "            cv2.imshow(\"show image\",draw_axis(image,pitch_label,yaw_label,roll_label))\n",
    "\n",
    "            cv2.waitKey(0) \n",
    "            cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_axis_and_points_pred(random_file = 'image00053'):\n",
    "    faceModule = mediapipe.solutions.face_mesh\n",
    "    with faceModule.FaceMesh(static_image_mode=True) as faces:\n",
    "        image = cv2.imread('AFLW2000/'+random_file+'.jpg')\n",
    "        results = faces.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        if results.multi_face_landmarks != None: \n",
    "            for face in results.multi_face_landmarks:\n",
    "                for landmark in face.landmark:\n",
    "                    x = landmark.x\n",
    "                    y = landmark.y\n",
    "                # note: the x and y values are scaled to the their width and height so we will get back their actual value in the image\n",
    "                    shape = image.shape \n",
    "                    relative_x = int(x * shape[1])\n",
    "                    relative_y = int(y * shape[0])\n",
    "\n",
    "                # cv2.putText(image, str(relative_y), (int(relative_x),int(relative_y)), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,255,0), 2)\n",
    "                    cv2.circle(image, (relative_x, relative_y), radius=1, color=(0, 255, 0), thickness=2)\n",
    "            cv2.imshow(\"show image\",draw_axis(image,pitch_label,yaw_label,roll_label))\n",
    "\n",
    "            cv2.waitKey(0) \n",
    "            cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test ploting axis and points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_file = 'image00052'\n",
    "plot_axis_on_image(random_file)\n",
    "draw_axis_and_points(random_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get fetures for specific image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(random_file = 'image00053'): # for specific image\n",
    "\n",
    "  faceModule = mediapipe.solutions.face_mesh \n",
    "  with faceModule.FaceMesh(static_image_mode=True) as faces: # creating object from FaceMesh class\n",
    "    image = cv2.imread('AFLW2000/'+random_file+'.jpg')\n",
    "    results = faces.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    if results.multi_face_landmarks != None:\n",
    "      face = results.multi_face_landmarks[0]\n",
    "      X = []\n",
    "      Y = []\n",
    "      for landmark in face.landmark:\n",
    "          x = landmark.x\n",
    "          y = landmark.y\n",
    "\n",
    "          shape = image.shape\n",
    "          relative_x = int(x * shape[1])\n",
    "          relative_y = int(y * shape[0])\n",
    "          X.append(relative_x)\n",
    "          Y.append(relative_y)\n",
    "      X_points = np.array(X).reshape(1,-1)\n",
    "      Y_points = np.array(Y).reshape(1,-1)\n",
    "\n",
    "\n",
    "      Center_X = X_points - X_points[:,99].reshape(-1,1)\n",
    "      Center_Y = Y_points - Y_points[:,99].reshape(-1,1)\n",
    "\n",
    "      # normalizing the data to be in the same scale by dividing over the distance between point 10 and point 171\n",
    "      X_171 = X_points[:,171]\n",
    "      X_10 = X_points[:,10]\n",
    "      Y_171 = Y_points[:,171]\n",
    "      Y_10 = Y_points[:,10]\n",
    "\n",
    "      distance = np.linalg.norm(np.array((X_10,Y_10)) - np.array((X_171,Y_171)),axis = 0).reshape(-1,1)\n",
    "      Norm_X = Center_X / distance\n",
    "      Norm_Y = Center_Y / distance\n",
    "\n",
    "      tdx=X_points[:,99]\n",
    "      tdy=Y_points[:,99]\n",
    "\n",
    "\n",
    "      features = np.hstack([Norm_X,Norm_Y])\n",
    "      \n",
    "      return features,tdx,tdy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test prediction axis in image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_file = 'image00002'\n",
    "img_feture,tdx,tdy=get_features(random_file)\n",
    "pitch_pred=svr_winner_pitch.predict(img_feture)\n",
    "\n",
    "yaw_pred=svr_winner_yaw.predict(img_feture)\n",
    "\n",
    "roll_pred=svr_winner_roll.predict(img_feture)\n",
    "\n",
    "image = cv2.imread('AFLW2000/'+random_file+'.jpg')\n",
    "cv2.imshow(\"show image\",draw_axis(image,pitch_pred,yaw_pred,roll_pred,tdx,tdy))\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Queue:\n",
    "    # defining the constructor\n",
    "    def __init__(self,max_size):\n",
    "        self.queue = []\n",
    "        self.length = 0\n",
    "        self.max_size = max_size\n",
    "    \n",
    "    # adding values to the queue\n",
    "    def enqueue(self,x):\n",
    "        if self.length < self.max_size:\n",
    "          self.queue.append(x)\n",
    "          self.length = self.length+1\n",
    "        else:\n",
    "          print(\"You have reached the maximum size\") \n",
    "    # removing values from the queue\n",
    "    def dequeue(self):\n",
    "        if len(self.queue) > 0:\n",
    "            removed = self.queue[0]\n",
    "            del self.queue[0]\n",
    "            self.length = self.length-1\n",
    "            return removed\n",
    "        else:\n",
    "            print(\"Queue is Empty\")\n",
    "\n",
    "    # checking if the queue is full\n",
    "    def IsFull(self):\n",
    "      if self.length == self.max_size:\n",
    "        return True\n",
    "    \n",
    "    # printing the queue values\n",
    "    def print_queue(self):\n",
    "        for i in self.queue:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a VideoCapture object and read from input file\n",
    "def Create_TestVideo(pitch_model,yaw_model,roll_model,smoothing = False,size = 30):\n",
    "\n",
    "  cap = cv2.VideoCapture('AFLW2000/test.mp4')\n",
    "  width= int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "  height= int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "  # Check if camera opened successfully\n",
    "  if (cap.isOpened()== False): \n",
    "      print(\"Error opening video file\")\n",
    "\n",
    "  \n",
    "  pitch_queue = Queue(max_size = size)\n",
    "  yaw_queue = Queue(max_size = size)\n",
    "  roll_queue = Queue(max_size = size)\n",
    "\n",
    "  # initializing a list to store the frames   \n",
    "  img_array = []\n",
    "  # Read until video is completed\n",
    "  while(cap.isOpened()):   \n",
    "    # Capture frame-by-frame\n",
    "      ret, frame = cap.read()\n",
    "      if ret == True:\n",
    "        with faceModule.FaceMesh(static_image_mode=True) as face:\n",
    "          # processing the image to detect the face and then generating the land marks (468 for each x,y,z).\n",
    "          results = face.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "          if results.multi_face_landmarks != None:\n",
    "            for face in results.multi_face_landmarks:\n",
    "                # initializing X and Y lists to store the spacial coordinates of the points\n",
    "                X = []\n",
    "                Y = []\n",
    "                # looping over the landmarks to extract x and y\n",
    "                for j,landmark in enumerate(face.landmark):\n",
    "                    x = landmark.x\n",
    "                    y = landmark.y\n",
    "                    # retrieve the true values of x and y\n",
    "                    shape = frame.shape \n",
    "                    relative_x = int(x * shape[1])\n",
    "                    relative_y = int(y * shape[0])\n",
    "                    X.append(relative_x)\n",
    "                    Y.append(relative_y)\n",
    "\n",
    "                X = np.array(X)\n",
    "                Y = np.array(Y)\n",
    "                # centering the data arround the point 99\n",
    "                X_center = X - X[99]\n",
    "                Y_center = Y - Y[99]\n",
    "                d = np.linalg.norm(np.array((X[171],Y[171])) - np.array((X[10],Y[10])))\n",
    "                X_norm = X_center/d\n",
    "                Y_norm = Y_center/d\n",
    "                X_norm = X_norm\n",
    "                Y_norm = Y_norm\n",
    "                points = np.hstack([X_norm,Y_norm]).reshape(1,-1)\n",
    "                # predicting the 3 angels to draw the axis on the image\n",
    "                pred_pitch = pitch_model.predict(points)\n",
    "                pred_yaw = yaw_model.predict(points)\n",
    "                pred_roll = roll_model.predict(points)\n",
    "                \n",
    "                if smoothing  == True:\n",
    "                  if not pitch_queue.IsFull(): \n",
    "                    pitch_queue.enqueue(pred_pitch)\n",
    "                    yaw_queue.enqueue(pred_yaw)\n",
    "                    roll_queue.enqueue(pred_roll)\n",
    "                  else:\n",
    "                    pitch_queue.dequeue()\n",
    "                    yaw_queue.dequeue()\n",
    "                    roll_queue.dequeue()\n",
    "                    pitch_queue.enqueue(pred_pitch)\n",
    "                    yaw_queue.enqueue(pred_yaw)\n",
    "                    roll_queue.enqueue(pred_roll)\n",
    "\n",
    "                  pitch = sum(pitch_queue.queue)/len(pitch_queue.queue)\n",
    "                  yaw = sum(yaw_queue.queue)/len(yaw_queue.queue)\n",
    "                  roll = sum(roll_queue.queue)/len(roll_queue.queue)\n",
    "                  draw_axis(frame,pitch,yaw,roll,X[1],Y[1])\n",
    "\n",
    "                else:\n",
    "                  draw_axis(frame,pred_pitch,pred_yaw,pred_roll,X[1],Y[1])\n",
    "                # appending the result frame to the img_array list\n",
    "                img_array.append(frame)\n",
    "      # Break the loop\n",
    "      else: \n",
    "          break\n",
    "  cap.release()  \n",
    "  # Closes all the frames\n",
    "  cv2.destroyAllWindows()\n",
    "  print(\"Number of Detected Frames = \",len(img_array))\n",
    "  # converting the frames to video\n",
    "  out = cv2.VideoWriter('out.mp4',cv2.VideoWriter_fourcc(*'DIVX'), 20, (width,height))\n",
    "  for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "  out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Detected Frames =  749\n"
     ]
    }
   ],
   "source": [
    "Create_TestVideo(svr_winner_pitch,svr_winner_yaw,svr_winner_roll,smoothing =True,size = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled8.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "7992c1b1f2096d4df0e8ae34c970e3d97cf8fa601abd01de771a7c2ed49030bf"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "191d4705883b4147ab9061dc72745e5b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "199157f2da9f415c9580375d918490e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_619c2167a7a74b5bb9e7305470298210",
       "IPY_MODEL_ee03e3c503d24af7aad0ee59edee3194",
       "IPY_MODEL_63a19b88efc84fb6a8d4f89690e5ab20"
      ],
      "layout": "IPY_MODEL_4a26d0eced5742b2a0cf838654d3cb0e"
     }
    },
    "21867022fd64479abff2c9fb8a494e12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3bb330ce79ab44319d13c7d6f1a7f524": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3c0c598e83b84124a59dfb15235285ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "400fa7d5acc64029a7c5d2e41ce393cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa334c3ce53948a2918cc3a3a1056296",
      "max": 300,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5b7c8887a3674ccb91639d0b7a87f985",
      "value": 22
     }
    },
    "4a26d0eced5742b2a0cf838654d3cb0e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50739340db90463c89c4ef0fafca6196": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56f4fc27b4ab447fb5b200ce994060e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b7c8887a3674ccb91639d0b7a87f985": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "619c2167a7a74b5bb9e7305470298210": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21867022fd64479abff2c9fb8a494e12",
      "placeholder": "​",
      "style": "IPY_MODEL_a262a954ca0f41898243c68df10c4f4d",
      "value": "100%"
     }
    },
    "63a19b88efc84fb6a8d4f89690e5ab20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a5cdcc9dbd6b427182d352e084e66e3d",
      "placeholder": "​",
      "style": "IPY_MODEL_d1edefd6e58a4aa38268295ed14a03fe",
      "value": " 2000/2000 [00:54&lt;00:00, 38.70it/s]"
     }
    },
    "64785eeb4d2f408d8fd485dfa2db9b8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c0c598e83b84124a59dfb15235285ba",
      "placeholder": "​",
      "style": "IPY_MODEL_3bb330ce79ab44319d13c7d6f1a7f524",
      "value": " 22/300 [16:07&lt;5:34:09, 72.12s/pipeline]"
     }
    },
    "65e812e3e67d4eb697b8779f411c79e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6e3bcb535c3b4c0b8fbf525b72c76b00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_84b6b198604f4a19ac22cb9ac1c5b16b",
       "IPY_MODEL_400fa7d5acc64029a7c5d2e41ce393cd",
       "IPY_MODEL_64785eeb4d2f408d8fd485dfa2db9b8a"
      ],
      "layout": "IPY_MODEL_56f4fc27b4ab447fb5b200ce994060e4"
     }
    },
    "84b6b198604f4a19ac22cb9ac1c5b16b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_50739340db90463c89c4ef0fafca6196",
      "placeholder": "​",
      "style": "IPY_MODEL_ee8a12ed12fc4c43bf12278fe5fa65f2",
      "value": "Optimization Progress:   7%"
     }
    },
    "a262a954ca0f41898243c68df10c4f4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a5cdcc9dbd6b427182d352e084e66e3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1edefd6e58a4aa38268295ed14a03fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee03e3c503d24af7aad0ee59edee3194": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_191d4705883b4147ab9061dc72745e5b",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_65e812e3e67d4eb697b8779f411c79e4",
      "value": 2000
     }
    },
    "ee8a12ed12fc4c43bf12278fe5fa65f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fa334c3ce53948a2918cc3a3a1056296": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
